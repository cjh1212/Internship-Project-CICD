name: train

on:
  push:
    branches:
      - dev
    
jobs:
  data_collection:
    name: data_collection
    runs-on: ubuntu-latest
    steps:
      - name: Check
        uses: actions/checkout@v3
      - name: python_packages
        run: python -m pip install --upgrade pip
          pip install pandas sklearn transformers datasets Beautifulsoup4
      - name: collection
        run: python3 collection.py
        
  upload:
    name: upload
    runs-on: ubuntu-latest
    needs: data_collection
    permissions:
      contents: 'read'
      id-token: 'write'
    steps:
      - name: Check
        uses: actions/checkout@v3
      - id: 'auth'
        uses: 'google-github-actions/auth@v0'
        with:
          credentials_json: '${{ secrets.gcp_credentials }}'
      - id: 'upload_data'
        uses: 'google-github-actions/upload-cloud-storage@v0'
        with:
          path: './train_data.csv'
          destination: 'bucket_cjh980803'
      - name: Set up cloud SDK
        uses: google-github-actions/setup-gcloud@v0
      - run: |-
          gsutil cp gs://bucket_cjh980803/train_data.csv .
          gcloud compute scp ./train_data.csv cjh980803@instance:~/ --zone=asia-northeast3-a
          
  train:
    name: train
    runs-on: ubuntu-latest
    needs: upload
    steps:
      - name: test
        uses: appleboy/ssh-action@master
        with:
          host: ${{ secrets.SSH_HOST }}
          username: ${{ secrets.SSH_USERNAME }}
          key: ${{ secrets.SSH_PASSWORD }}
          port: ${{ secrets.SSH_PORT }}
          script: python3 preprocessing_train.py
    
